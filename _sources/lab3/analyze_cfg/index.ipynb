{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Анализ накачек языка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализация импортируемых классов находится [здесь](https://github.com/SmEgDm/tfl/tree/main/labs/lab3/analyze_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import reduce\n",
    "from graphviz import Digraph\n",
    "\n",
    "from CFG import CFG\n",
    "from Term import Term\n",
    "from Node import Node\n",
    "from Test import Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поиск регулярных подмножеств"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regular_subset(cfg: CFG):\n",
    "    subset = set()\n",
    "    for nterm in cfg.get_nterms():\n",
    "        is_regular = True\n",
    "        for rule in cfg.rules_with_left_side(nterm):\n",
    "            if not rule.is_right_linear():\n",
    "                is_regular = False\n",
    "        if is_regular:\n",
    "            subset.add(nterm)\n",
    "    \n",
    "    changed = True\n",
    "    while changed:\n",
    "        changed = False\n",
    "        irregular_nterms = set()\n",
    "        for nterm in subset:\n",
    "            for rule in cfg.rules_with_left_side(nterm):\n",
    "                for term in rule.right_side:\n",
    "                    if term.is_nterm() and term not in subset:\n",
    "                        irregular_nterms.add(nterm)\n",
    "                        changed = True\n",
    "        \n",
    "        for nterm in irregular_nterms:\n",
    "            if nterm in subset:\n",
    "                subset.remove(nterm)\n",
    "\n",
    "    return subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дерево накачек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PumpTree:\n",
    "    def _dfs(term, start_nterm, cfg, visited):\n",
    "        if not term.is_nterm():\n",
    "            return (Node(term), False)\n",
    "        \n",
    "        if term in visited:\n",
    "            if term == start_nterm:\n",
    "                return (Node(term), True)\n",
    "            return (None, False)\n",
    "\n",
    "        for rule in cfg.rules_with_left_side(term):\n",
    "            node = Node(term)\n",
    "            found = False\n",
    "            for child_term in rule.right_side:\n",
    "                if found:\n",
    "                    child = Node(child_term)\n",
    "                else:\n",
    "                    visited.add(term)\n",
    "                    child, found = PumpTree._dfs(\n",
    "                        child_term, \n",
    "                        start_nterm, \n",
    "                        cfg, \n",
    "                        visited\n",
    "                    )\n",
    "                    if child == None:\n",
    "                        break\n",
    "                node.add_child(child)\n",
    "            \n",
    "            if found:\n",
    "                return (node, True)\n",
    "        \n",
    "        return (None, False)\n",
    "    \n",
    "    def __init__(self, pump_nterm, cfg):\n",
    "        Node.set_id(0)\n",
    "        self.root, _ = PumpTree._dfs(pump_nterm, pump_nterm, cfg, set())\n",
    "    \n",
    "    def get_pumping(self):\n",
    "        pumping = self.root.get_pumping()\n",
    "        separator_index = pumping.index(self.root.term)\n",
    "\n",
    "        return pumping[0:separator_index], pumping[separator_index + 1:]\n",
    "\n",
    "    def to_graphviz(self):\n",
    "        digraph = Digraph(format='svg')\n",
    "        self.root.to_graphviz(digraph)\n",
    "        \n",
    "        return digraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка $\\Phi_1 \\in L(\\Phi_2^{+})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def belongs_to_language(f1, f2, cfg):\n",
    "    def rec(f1_suffix, f2_suffix):\n",
    "        f1_suffix = list(f1_suffix)\n",
    "        f2_suffix = list(f2_suffix)\n",
    "        while (\n",
    "            len(f1_suffix) != 0 and\n",
    "            len(f2_suffix) != 0 and\n",
    "            f1_suffix[0] == f2_suffix[0]\n",
    "        ):\n",
    "            f1_suffix.pop(0)\n",
    "            f2_suffix.pop(0)\n",
    "        \n",
    "        if len(f1_suffix) == 0:\n",
    "            return True\n",
    "        if len(f2_suffix) == 0:\n",
    "            return len(f2) != 0 and rec(f1_suffix, f2)\n",
    "        if not f2_suffix[0].is_nterm():\n",
    "            return False\n",
    "        \n",
    "        return reduce(\n",
    "            lambda result, rule:\n",
    "                result or rec(\n",
    "                    f1_suffix,\n",
    "                    rule.right_side + f2_suffix[1:]\n",
    "                ),\n",
    "            cfg.rules_with_left_side(f2_suffix[0]),\n",
    "            False\n",
    "        )\n",
    "    \n",
    "    return rec(f1, f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Развертка нетерминала"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfold(unfold_nterm: Term, cfg: CFG):\n",
    "    used_nterms = set()\n",
    "    def rec(nterm):\n",
    "        if nterm in used_nterms:\n",
    "            return []\n",
    "        \n",
    "        words = []\n",
    "        for rule in cfg.rules_with_left_side(nterm):\n",
    "            new_words = [[]]\n",
    "            for term in rule.right_side:\n",
    "                if not term.is_nterm():\n",
    "                    for i in range(len(new_words)):\n",
    "                        new_words[i] += [term]\n",
    "                else:\n",
    "                    used_nterms.add(nterm)\n",
    "                    suffixes = rec(term)\n",
    "                    for i in range(len(new_words)):\n",
    "                        for j in range(len(suffixes)):\n",
    "                            new_words[i] += suffixes[j]\n",
    "            words += new_words\n",
    "        \n",
    "        min_length = min([len(word) for word in words])\n",
    "        result = []\n",
    "        for word in words:\n",
    "            if len(word) == min_length:\n",
    "                result.append(word)\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    return rec(unfold_nterm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рекурсивное замыкание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clousure(regular_nterms, possibly_regular_nterms, cfg):    \n",
    "    changed = True\n",
    "    while changed:\n",
    "        changed = False\n",
    "        for nterm in cfg.get_nterms():\n",
    "            if (\n",
    "                nterm in regular_nterms or \n",
    "                nterm in possibly_regular_nterms\n",
    "            ): continue\n",
    "\n",
    "            is_regular = is_possibly_regular = True\n",
    "            for rule in cfg.rules_with_left_side(nterm):\n",
    "                for term in rule.right_side:\n",
    "                    if term.is_nterm() and term not in regular_nterms:\n",
    "                        is_regular = False\n",
    "                        if term not in possibly_regular_nterms:\n",
    "                            is_possibly_regular = False\n",
    "            \n",
    "            if is_regular:\n",
    "                regular_nterms.add(nterm)\n",
    "                changed = True\n",
    "            elif is_possibly_regular:\n",
    "                possibly_regular_nterms.add(nterm)\n",
    "                changed = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(cfg):\n",
    "    regular_nterms = regular_subset(cfg)\n",
    "    suspicious_nterms = set()\n",
    "    possibly_regular_nterms = set()\n",
    "    trees = []\n",
    "\n",
    "    for nterm in cfg.get_nterms():\n",
    "        if nterm in regular_nterms:\n",
    "            continue\n",
    "\n",
    "        pump_tree = PumpTree(nterm, cfg)\n",
    "\n",
    "        if pump_tree.root != None:\n",
    "            f1, f2 = pump_tree.get_pumping()\n",
    "\n",
    "            f2_contains_irregular_nterms = False\n",
    "            for term in f2:\n",
    "                if term.is_nterm() and term not in regular_nterms:\n",
    "                    f2_contains_irregular_nterms = True\n",
    "                    break\n",
    "\n",
    "            if (\n",
    "                f2_contains_irregular_nterms or \n",
    "                not belongs_to_language(f1, f2, cfg)\n",
    "            ):\n",
    "                suspicious_nterms.add(nterm)\n",
    "                trees.append(pump_tree)\n",
    "                continue\n",
    "\n",
    "            all_belongs = True\n",
    "            for word in unfold(nterm, cfg):\n",
    "                if not belongs_to_language(word, f2, cfg):\n",
    "                    all_belongs = False\n",
    "                    break\n",
    "            if all_belongs:\n",
    "                possibly_regular_nterms.add(nterm)\n",
    "        \n",
    "    clousure(regular_nterms, possibly_regular_nterms, cfg)\n",
    "\n",
    "    return (\n",
    "        regular_nterms,\n",
    "        possibly_regular_nterms,\n",
    "        suspicious_nterms,\n",
    "        trees\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тесты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdb124677d264f048beb5863206b969e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(HTML(value='\\n            <div>\\n                <p>\\n                    <b>КС-грамматика</b><b…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from Test import TESTS\n",
    "\n",
    "TESTS_DIR = 'tests'\n",
    "\n",
    "for test_name in os.listdir(TESTS_DIR):\n",
    "    Test(\n",
    "        test_name.split('.')[0], \n",
    "        os.path.join(TESTS_DIR, test_name)\n",
    "    ).execute(analyze)\n",
    "\n",
    "Test.display_results()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
